<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title> Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis</title>

  <link rel="icon" href="./static/images/video-mme.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <link rel="stylesheet" href="./static/css/video-player.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

  

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a> -->
      <!-- @PAN TODO: consider adding links? -->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">
            <b>Awesome-MLLM</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation">
            <b>MME</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://github.com/BradyFU/Woodpecker">
            <b>Woodpecker</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/video-mme.png" style="width:1.6em;vertical-align: middle" alt="Logo"/>
            <span class="mathvista" style="vertical-align: middle">Video-MME</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis
            <!-- <br> -->
            <!-- with GPT-4V, Bard, and Other Large Multimodal Models -->
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/BradyFU">Chaoyou Fu,</a></span>
            <span class="author-block">
              <a href="https://dirkiedai.github.io/">Yuhan Dai</a><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/Leon1207">Yongdong Luo</a><sup style="color:#ed4b82;">2</sup>,
            </span>
            
            <span class="author-block">
              <a href="">Lei Li</a><sup style="color:#ed4b82">3</sup>,
            </span>
            <span class="author-block">
              <a href="">Shuhuai Ren</a><sup style="color:#ffac33">4</sup>,
            </span>
            <span class="author-block">
              <a href="">Renrui Zhang</a><sup style="color:#18acfb">5</sup>,
            </span>
            <span class="author-block">
              <a href="">Zihan Wang</a><sup style="color:#33ffd6">6</sup>,
            </span>
            <span class="author-block">
              <a href="">Chenyu Zhou</a><sup style="color:#ed4b82">2</sup>,
            </span>
            <span class="author-block">
              <a href="">Yunhang Shen</a>,
            </span>
            <span class="author-block">
              <a href="">Mengdan Zhang</a>,
            </span>
            <span class="author-block">
              <a href="">Peixian Chen</a>,
            </span>
            <span class="author-block">
              <a href="">Yanwei Li</a><sup style="color:#18acfb">5</sup>,
            </span>
            <span class="author-block">
              <a href="">Shaohui Lin</a><sup style="color:#33ffd6">6</sup>,
            </span>
            <span class="author-block">
              <a href="">Sirui Zhao</a><sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a href="">Ke Li</a>,
            </span>
            <span class="author-block">
              <a href="">Tong Xu</a><sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a href="">Xiawu Zheng</a><sup style="color:#ed4b82;">2</sup>,
            </span>
            <span class="author-block">
              <a href="">Enhong Chen</a><sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a href="">Rongrong Ji</a><sup style="color:#ed4b82;">2</sup>,
            </span>
            <span class="author-block">
              <a href="">Xing Sun</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>USTC,</span>
            <span class="author-block"><sup style="color:#ed4b82">2</sup>Xiamen University,</span>
            <span class="author-block"><sup style="color:#9400D3">3</sup>The University of Hong Kong,</span><br>
            <span class="author-block"><sup style="color:#ffac33">4</sup>Peking University,</span>
            <span class="author-block"><sup style="color:#18acfb">5</sup>CUHK,</span>
            <span class="author-block"><sup style="color:#33ffd6">6</sup>East China Normal University</span><br>
            
           

            <!-- <span class="paper-block"><b style="color:#f41c1c">ICLR 2024 Oral</b> (85 in 7304, 1.2%)</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                <!-- <a href="https://lupantech.github.io/papers/arxiv23_mathvista.pdf"
                   class="external-link button is-normal is-rounded is-dark"> -->
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/BradyFU/Video-MME"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#downloads"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">üîó</p>
                  </span>
                  <span>Dataset</span>
                </a>
              </span> 
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          In the quest for artificial general intelligence, Multi-modal Large Language Models (MLLMs) have emerged as a focal point in recent advancements. However, the predominant focus remains on developing their capabilities in static image understanding. The potential of MLLMs in processing sequential visual data is still insufficiently explored, highlighting the absence of a comprehensive, high-quality assessment of their performance. In this paper, we introduce <strong>Video-MME</strong>, the first-ever full-spectrum, <strong>M</strong>ulti-<strong>M</strong>odal <strong>E</strong>valuation benchmark of MLLMs in <strong>Video analysis</strong>. Our work distinguishes from existing benchmarks through four key features: 
            <strong>1) Diversity in video types</strong>, spanning 5 primary visual domains with 30 subfields to ensure broad scenario generalizability;
            <strong>2) Duration in temporal dimension</strong>, encompassing both short-, medium-, and long-term videos, ranging from 11 seconds to 1 hour, for robust contextual dynamics;
            <strong>3) Breadth in data modalities</strong>, integrating multi-modal inputs besides video frames, including subtitles and audios, to unveil the all-round capabilities of MLLMs;
            <strong>4) Quality in annotations</strong>, utilizing rigorous manual labeling by expert annotators to facilitate precise and reliable model assessment. 
            900 videos with a total of 256 hours are manually selected and annotated by repeatedly viewing all the video content, resulting in 2,700 question-answer pairs.
            With Video-MME, we extensively evaluate various state-of-the-art MLLMs, including GPT-4 series and Gemini 1.5 Pro, as well as open-source image models like InternVL-Chat-V1.5 and video models like LLaVA-NeXT-Video.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="section">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">

        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <p class="mt-3">Accuracy scores on Video-MME, including results for short, medium, and long videos with or without subtitles as input.
          </p>
          <div class="video-duration">
            <p>
              <strong>Short Video:</strong> 30s ~ 2min  &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
              <strong>Medium Video:</strong> 4min ~ 15min  &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
              <strong>Long Video:</strong> 30min ~ 60min
            </p>
          </div>

          <table class="js-sort-table" id="results">
            <thead>
              <tr>
                <th rowspan="2" style="vertical-align: middle;"><strong>#</strong></th>
                <th rowspan="2" style="vertical-align: middle;"><strong>Model</strong></th>
                <th rowspan="2" style="vertical-align: middle;"><strong>LLM <br>Params</strong></th>
                <th rowspan="2" style="vertical-align: middle;"><strong>Date</strong></th>
                <th colspan="2" style="vertical-align: middle;"><strong>Overall (%)</strong></th>
                <th colspan="2" style="vertical-align: middle;"><strong>Short Video (%)</strong></th>
                <th colspan="2" style="vertical-align: middle;"><strong>Medium Video (%)</strong></th> 
                <th colspan="2" style="vertical-align: middle;"><strong>Long Video (%)</strong></th> 
              </tr>
              <tr>
                <th><strong>w/o subtitles</strong></th>
                <th><strong>w subtitles</strong></th>
                <th><strong>w/o subtitles</strong></th>
                <th><strong>w subtitles</strong></th>
                <th><strong>w/o subtitles</strong></th>
                <th><strong>w subtitles</strong></th>
                <th><strong>w/o subtitles</strong></th>
                <th><strong>w subtitles</strong></th>
              </tr>
            </thead>
            <tbody>

              <tr>
                <td>1</td>
                <td><b class="best-score-text">Gemini 1.5 Pro ü•á</b></td>
                <td>- </td>
                <td>2024-5-27</td>

                <td><b class="best-score-text">75.7</b></td>
                <td><b class="best-score-text">81.6</b></td>
                <td>82.5</td>
                <td>84.4</td>
                <td>75.0</td>
                <td>82.3</td>
                <td>66.3</td>
                <td>76.0</td>                                 
              </tr>
              <tr>
                <td>2</td>
                <td><b class="best-score-text"><b class="best-score-text">GPT-4o ü•à</b></td>
                <td>- </td>
                <td>2024-5-27</td>

                <td><b class="best-score-text">66.2</b></td>
                <td><b class="best-score-text">65.8</b></td>
                <td>77.1</td>
                <td>77.5</td>
                <td>62.1</td>
                <td>63.0</td>
                <td>59.2</td> 
                <td>56.7</td>                           
              </tr>
              <tr>
                <td>3</td>
                <td><b class="best-score-text">GPT-4 Vision ü•â</b></td>
                <td>- </td>
                <td>2024-5-27</td>

                <td><b class="best-score-text">60.7</b></td>
                <td><b class="best-score-text">63.7</b></td>
                <td>71.4 </td>
                <td>74.5 </td>
                <td>56.5 </td>
                <td>59.3 </td>
                <td>54.2 </td>   
                <td>57.2 </td>                       
              </tr>
              <tr>
                <td>4</td>
                <td><b class=""><a href="https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/" class="ext-link" style="font-size: 16px;">LLaVA-NeXT-Video</a></b></td>
                <td>34B</td>
                <td>2024-5-27</td>

                <td><strong>52.5</strong></td>
                <td><strong>56.0</strong></td>
                <td>61.8</td>
                <td>65.9</td>
                <td>50.7</td>
                <td>54.1</td>
                <td>45.0</td>
                <td>48.1</td>                                 
              </tr>
              
              <tr>
                <td>5</td>
                <td><b class=""><a href="https://github.com/OpenGVLab/InternVL" class="ext-link" style="font-size: 16px;">InternVL-Chat-V1.5</a></b></td>
                <td>20B</td>
                <td>2024-5-27</td>

                <td><strong>51.5</strong></td>
                <td><strong>53.2</strong></td>
                <td>61.2</td>
                <td>62.4</td>
                <td>47.3</td>
                <td>50.0</td>
                <td>46.0</td>
                <td>47.0</td>                                 
              </tr>
              <tr>
                <td>6</td>
                <td><b class=""><a href="https://github.com/QwenLM/Qwen-VL" class="ext-link" style="font-size: 16px;">Qwen-VL-Max</a></b></td>
                <td>-</td>
                <td>2024-5-27</td>

                <td><strong>51.8</strong></td>
                <td><strong>51.7</strong></td>
                <td>56.5</td>
                <td>58.3</td>
                <td>49.9</td>
                <td>49.8</td>
                <td>49.0</td>
                <td>46.9</td>                                 
              </tr>
              <tr>
                <td>7</td>
                <td><b class=""><a href="https://github.com/PKU-YuanGroup/Chat-UniVi" class="ext-link" style="font-size: 16px;">Chat-UniVi-7B-v1.5</a></b></td>
                <td>7B</td>
                <td>2024-5-27</td>

                <td><strong>41.2</strong></td>
                <td><strong>46.3</strong></td>
                <td>46.3</td>
                <td>51.4</td>
                <td>40.3</td>
                <td>45.2</td>
                <td>36.9</td>
                <td>42.3</td>                                 
              </tr>
              <tr>
                <td>8</td>
                <td><b class=""><a href="https://github.com/TencentARC/ST-LLM" class="ext-link" style="font-size: 16px;">ST-LLM</a></b></td>
                <td>7B</td>
                <td>2024-5-27</td>

                <td><strong>38.6</strong></td>
                <td><strong>43.2</strong></td>
                <td>47.0</td>
                <td>49.9</td>
                <td>36.9</td>
                <td>42.2</td>
                <td>31.8</td>
                <td>37.3</td>                              
              </tr>
              <tr>
                <td>9</td>
                <td><b class=""><a href="https://github.com/PKU-YuanGroup/Video-LLaVA" class="ext-link" style="font-size: 16px;">Video-LLaVA</a></b></td>
                <td>7B</td>
                <td>2024-5-27</td>
                <td><strong>40.4</strong></td>
                <td><strong>42.3</strong></td>
                <td>45.9</td>
                <td>47.1</td>
                <td>38.1</td>
                <td>40.2</td>
                <td>37.3</td>
                <td>39.6</td>                                
              </tr>
              <tr>
                <td>10</td>
                <td><b class=""><a href="https://github.com/QwenLM/Qwen-VL" class="ext-link" style="font-size: 16px;">Qwen-VL-Chat</a></b></td>
                <td>7B</td>
                <td>2024-5-27</td>

                <td><strong>40.9</strong></td>
                <td><strong>41.7</strong></td>
                <td>44.5</td>
                <td>50.0</td>
                <td>35.3</td>
                <td>40.8</td>
                <td>30.7</td>
                <td>37.9</td>                              
              </tr>
              <tr>
                <td>11</td>
                <td><b class=""><a href="https://github.com/OpenGVLab/Ask-Anything/tree/main/video_chat2" class="ext-link" style="font-size: 16px;">VideoChat2</a></b></td>
                <td>7B</td>
                <td>2024-5-27</td>
                <td><strong>33.7</strong></td>
                <td><strong>35.9</strong></td>
                <td>38.2</td>
                <td>41.6</td>
                <td>33.2</td>
                <td>34.3</td>
                <td>29.7</td>
                <td>31.9</td>                               
              </tr>
              
          
             
          </tbody>                                                   
        </table> 

        </div>

      </div>
    </div>

  </div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mathvista_other">
    <span class="mathvista_other" style="vertical-align: middle">Benchmark</span>
  </h1>
  </div>
</section>
            
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths" style="width: 100%;">
        <h2 class="title is-3">Examples</h2>
        <div class="content has-text-justified">

        <div id="results-carousel" class="carousel results-carousel">  
          
            <div class="content has-text-centered">

              <img src="static/images/highlight_video/VFntoBRGF1A.png" style="width: 95%;"/>
              <p style="margin-bottom: 30px;">üîó Full Video Link: <a href="https://www.youtube.com/watch?v=VFntoBRGF1A">VFntoBRGF1A</a></p>
            
            </div>
          
            <div class="content has-text-centered">

              <img src="static/images/highlight_video/p84O3JAp_IM.png" style="width: 95%;"/>
              <p style="margin-bottom: 30px;">üîó Full Video Link: <a href="https://www.youtube.com/watch?v=p84O3JAp_IM">p84O3JAp_IM</a></p>
            
            </div>

            <div class="content has-text-centered">

              <img src="static/images/highlight_video/AF8d72mA41M.png" style="width: 95%;"/>
              <p style="margin-bottom: 30px;">üîó Full Video Link: <a href="https://www.youtube.com/watch?v=AF8d72mA41M">AF8d72mA41M</a></p>
            
            </div>

            <div class="content has-text-centered">

              <img src="static/images/highlight_video/pwVJizpCuDQ.png" style="width: 95%;"/>
              <p style="margin-bottom: 30px;">üîó Full Video Link: <a href="https://www.youtube.com/watch?v=pwVJizpCuDQ">pwVJizpCuDQ</a></p>
            
            </div>

        </div>

          
        </div>
      </div> 

        </div>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <h2 class="title is-3" style="margin-top: 30px;">Benchmark Category Hierarchy </h2>
          
          <!-- bing tu -->
          <div class="container-wrapper">
            <div id="container"></div>
            <div id="image-container">
              <img src="static/images/data_sta_2.png" alt="data-composition" style="max-width: 60%; display: inline-block; margin-right: 200px;"/>
            </div>
          </div>
        <script type="text/javascript" src="https://registry.npmmirror.com/echarts/5.5.0/files/dist/echarts.min.js"></script>
        <script type="text/javascript" src="static/js/bingtu.js"></script>

        <p style="text-align: center; margin-left: auto; margin-right: auto; width: 50%;"> 
            (Left) Video types category hierarchy of Video-MME, which covers 5 key domains and 30 sub-class video types. 
            (Right) Video duration length and question type distribution of Video-MME.
            Video-MME has a full spectrum of video length and covers different core abilities of LVLMs.<br/>
        </p>

        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <h2 class="title is-3">Benchmark Comparison</h2>
          <img src="static/images/dataset_comparsion.png" alt="data-composition" style="max-width: 50%;"/>
          <p style="text-align: center; margin-left: auto; margin-right: auto; width: 50%;" >
            The comparison of various benchmarks encompasses several key aspects: 
                the total number of videos, the number of clips, the average duration of the videos, the method of video annotation (manual denoted as M, automated as A), 
                the average number of QA pair tokens, the average number of subtitle tokens, whether the videos cover multiple duration levels, 
                whether the videos are sourced from a broad range of open domains and whether provide audio. 
                It is important to note that if a dataset includes multiple task formats, our comparison focuses solely on the multiple-choice segment.
          </p>
        </div>
      </div>
    </div>
    
  </div>
</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista_other">Experiment Results</h1>
  </div>
</section>

<section class="section">
  <div class="container">

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Results on Different Question Types</h2>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/exp_results/results_of_question_types.png" alt="grade-lv" width="50%"/>
              <p>Results of Gemini 1.5 Pro within different question types.</p>
            </div>
          </div>
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Results on Different Video Types</h2>

          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/exp_results/results_of_video_types.png" alt="" width="80%"/>
              <p>Results of Gemini 1.5 Pro within different video types.</p>
            </div>
          </div>

          <div class="box m-5">
            
            <div id="results-carousel" class="carousel results-carousel">  
            
              <div class="content has-text-centered">
                <img src="static/images/exp_results/results_of_video_sub_types-1.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">Results of Gemini 1.5 Pro within different question sub-types (1).</p>
              </div>
            
              <div class="content has-text-centered">
                <img src="static/images/exp_results/results_of_video_sub_types-2.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">Results of Gemini 1.5 Pro within different question sub-types (2).</p>
              </div>

              <div class="content has-text-centered">
                <img src="static/images/exp_results/results_of_video_sub_types-3.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">Results of Gemini 1.5 Pro within different question sub-types (3).</p>
              </div>

            </div>

          </div>

      </div>
    </div>

  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista_other" id="downloads">Dataset Application</h1>
  </div>
</section>

<section class="section">
  <div class="container" style="width: 60%;">
  <style>
      pre {
        background-color: #f4f4f4;
        padding: 5px; /* Ë∞ÉÊï¥padding‰∏∫5px */
        border: 1px solid #ddd;
        border-radius: 5px;
        overflow-x: auto; /* ÂÖÅËÆ∏Ê∞¥Âπ≥ÊªöÂä® */
    }
    code {
        font-family: Consolas, "Courier New", monospace;
        color: #d63384; /* ‰ª£Á†ÅÊñáÊú¨È¢úËâ≤ */
    }
  </style>

    <p style="text-align: center;">üåüüåü The benchmark dataset is for academic research only. </p>
    <br>
    <p style="text-align: center;"><strong>Requirement: </strong> Please fill in this <a href="">form</a> to access the dataset. </p>
    <br>


  </div>
</section>


<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align: center;">
            This website is adapted from <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>
